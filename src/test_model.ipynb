{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model: CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Load the model\n",
    "model, preprocess = clip.load('ViT-B/32', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "\n",
    "image_paths = ['../images/5536532658_3_1_1.jpg', '../images/5536532658_6_1_1.jpg', '../images/5767521712_3_1_1.jpg', '../images/81_0_2024_V_0_3.jpeg']\n",
    "\n",
    "images = [preprocess(Image.open(image_path)).unsqueeze(0).to(device) for image_path in image_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    image_features_l = [model.encode_image(image) for image in images]\n",
    "\n",
    "image_features = torch.stack(image_features_l).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between image 1 and 2 (same): 0.95849609375\n",
      "Similarity between image 1 and 3 (different): 0.7919921875\n"
     ]
    }
   ],
   "source": [
    "# Compute distances between similar and not\n",
    "\n",
    "cosine_similarity_same = torch.nn.functional.cosine_similarity(image_features_l[0], image_features_l[1])\n",
    "\n",
    "cosine_similarity_diff = torch.nn.functional.cosine_similarity(image_features_l[0], image_features_l[2])\n",
    "\n",
    "print(f\"Similarity between image 1 and 2 (same): {cosine_similarity_same.item()}\")\n",
    "\n",
    "print(f\"Similarity between image 1 and 3 (different): {cosine_similarity_diff.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between image 1 and 2: 0.912109375\n",
      "Similarity between image 2 and 3: 0.826171875\n",
      "Similarity between image 1 and 3: 0.75\n"
     ]
    }
   ],
   "source": [
    "image_paths = ['../images/11_0_2024_V_0_1.jpeg', '../images/11_1_2024_V_0_1.jpeg', '../images/11_2_2024_V_0_1.jpeg']\n",
    "\n",
    "images = [preprocess(Image.open(image_path)).unsqueeze(0).to(device) for image_path in image_paths]\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = [model.encode_image(image) for image in images]\n",
    "    \n",
    "    \n",
    "cosine_similarity_1_2 = torch.nn.functional.cosine_similarity(image_features[0], image_features[1])\n",
    "cosine_similarity_2_3 = torch.nn.functional.cosine_similarity(image_features[1], image_features[2])\n",
    "cosine_similarity_1_3 = torch.nn.functional.cosine_similarity(image_features[0], image_features[2])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Similarity between image 1 and 2: {cosine_similarity_1_2.item()}\")\n",
    "\n",
    "print(f\"Similarity between image 2 and 3: {cosine_similarity_2_3.item()}\")\n",
    "\n",
    "print(f\"Similarity between image 1 and 3: {cosine_similarity_1_3.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between image 1 and 2: 0.64453125\n",
      "Similarity between image 2 and 3: 0.78759765625\n",
      "Similarity between image 1 and 3: 0.576171875\n"
     ]
    }
   ],
   "source": [
    "image_paths = ['../images/models/96_0_2024_V_0_1', '../images/models/96_2_2024_V_0_1', '../images/models/100_2_2023_I_0_1']\n",
    "\n",
    "images = [preprocess(Image.open(image_path)).unsqueeze(0).to(device) for image_path in image_paths]\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = [model.encode_image(image) for image in images]\n",
    "    \n",
    "    \n",
    "cosine_similarity_1_2 = torch.nn.functional.cosine_similarity(image_features[0], image_features[1])\n",
    "cosine_similarity_2_3 = torch.nn.functional.cosine_similarity(image_features[1], image_features[2])\n",
    "cosine_similarity_1_3 = torch.nn.functional.cosine_similarity(image_features[0], image_features[2])\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Similarity between image 1 and 2: {cosine_similarity_1_2.item()}\")\n",
    "\n",
    "print(f\"Similarity between image 2 and 3: {cosine_similarity_2_3.item()}\")\n",
    "\n",
    "print(f\"Similarity between image 1 and 3: {cosine_similarity_1_3.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_data = np.array([\n",
    "    ['m', 's', 'v'],\n",
    "    ['m', 's', 'v'],\n",
    "    ['m', 'd', 'v'],\n",
    "    ['m', 's', 'v'],\n",
    "])\n",
    "\n",
    "weight = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoded_categorical = encoder.fit_transform(tabular_data).toarray()\n",
    "encoded_categorical = torch.tensor(encoded_categorical, device='cuda').float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = torch.cat((image_features, weight*encoded_categorical), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9890365600585938\n"
     ]
    }
   ],
   "source": [
    "similarity_score = torch.nn.functional.cosine_similarity(combined_features[0].unsqueeze(0), combined_features[1].unsqueeze(0))\n",
    "print(\"Cosine Similarity:\", similarity_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7012704610824585\n"
     ]
    }
   ],
   "source": [
    "similarity_score = torch.nn.functional.cosine_similarity(combined_features[0].unsqueeze(0), combined_features[2].unsqueeze(0))\n",
    "print(\"Cosine Similarity:\", similarity_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9810919165611267\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "similarity_score = torch.nn.functional.cosine_similarity(combined_features[0].unsqueeze(0), combined_features[3].unsqueeze(0))\n",
    "print(\"Cosine Similarity:\", similarity_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
